{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Bot QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqO0PRcFsPTe"
   },
   "source": [
    "### Datos\n",
    "El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n",
    "[LINK](http://convai.io/data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bDFC0I3j9oFD"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ut2uFcC8A08a",
    "outputId": "fff6f2bd-df05-4ec7-efc3-d9a781e3c88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\emel\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\emel\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\emel\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\emel\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\emel\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzFxeI8zFeci",
    "outputId": "93057a3b-198a-424c-c4cb-89ee81506c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\emel\\anaconda3\\lib\\site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cq3YXak9sGHd"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import requests\n",
    "import io\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ygb1x6aFYFl",
    "outputId": "670cbd13-3aae-4d74-b950-4f833c90ad52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHNkUaPp6aYq",
    "outputId": "d0a83095-26e9-423a-8720-92a6fded5d0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi, how are you doing?</td>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i'm fine. how about yourself?</td>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm pretty good. thanks for asking.</td>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no problem. so how have you been?</td>\n",
       "      <td>i've been great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i've been great. what about you?</td>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i've been good. i'm in school right now.</td>\n",
       "      <td>what school do you go to?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what school do you go to?</td>\n",
       "      <td>i go to pcc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i go to pcc.</td>\n",
       "      <td>do you like it there?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>do you like it there?</td>\n",
       "      <td>it's okay. it's a really big campus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it's okay. it's a really big campus.</td>\n",
       "      <td>good luck with school.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>good luck with school.</td>\n",
       "      <td>thank you very much.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>how's it going?</td>\n",
       "      <td>i'm doing well. how about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i'm doing well. how about you?</td>\n",
       "      <td>never better, thanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>never better, thanks.</td>\n",
       "      <td>so how have you been lately?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>so how have you been lately?</td>\n",
       "      <td>i've actually been pretty good. you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>i've actually been pretty good. you?</td>\n",
       "      <td>i'm actually in school right now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>i'm actually in school right now.</td>\n",
       "      <td>which school do you attend?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>which school do you attend?</td>\n",
       "      <td>i'm attending pcc right now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>i'm attending pcc right now.</td>\n",
       "      <td>are you enjoying it there?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>are you enjoying it there?</td>\n",
       "      <td>it's not bad. there are a lot of people there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>it's not bad. there are a lot of people there.</td>\n",
       "      <td>good luck with that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>good luck with that.</td>\n",
       "      <td>thanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>how are you doing today?</td>\n",
       "      <td>i'm doing great. what about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>i'm doing great. what about you?</td>\n",
       "      <td>i'm absolutely lovely, thank you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>i'm absolutely lovely, thank you.</td>\n",
       "      <td>everything's been good with you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>everything's been good with you?</td>\n",
       "      <td>i haven't been better. how about yourself?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>i haven't been better. how about yourself?</td>\n",
       "      <td>i started school recently.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>i started school recently.</td>\n",
       "      <td>where are you going to school?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>where are you going to school?</td>\n",
       "      <td>i'm going to pcc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>i'm going to pcc.</td>\n",
       "      <td>how do you like it so far?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question  \\\n",
       "0                           hi, how are you doing?   \n",
       "1                    i'm fine. how about yourself?   \n",
       "2              i'm pretty good. thanks for asking.   \n",
       "3                no problem. so how have you been?   \n",
       "4                 i've been great. what about you?   \n",
       "5         i've been good. i'm in school right now.   \n",
       "6                        what school do you go to?   \n",
       "7                                     i go to pcc.   \n",
       "8                            do you like it there?   \n",
       "9             it's okay. it's a really big campus.   \n",
       "10                          good luck with school.   \n",
       "11                                 how's it going?   \n",
       "12                  i'm doing well. how about you?   \n",
       "13                           never better, thanks.   \n",
       "14                    so how have you been lately?   \n",
       "15            i've actually been pretty good. you?   \n",
       "16               i'm actually in school right now.   \n",
       "17                     which school do you attend?   \n",
       "18                    i'm attending pcc right now.   \n",
       "19                      are you enjoying it there?   \n",
       "20  it's not bad. there are a lot of people there.   \n",
       "21                            good luck with that.   \n",
       "22                        how are you doing today?   \n",
       "23                i'm doing great. what about you?   \n",
       "24               i'm absolutely lovely, thank you.   \n",
       "25                everything's been good with you?   \n",
       "26      i haven't been better. how about yourself?   \n",
       "27                      i started school recently.   \n",
       "28                  where are you going to school?   \n",
       "29                               i'm going to pcc.   \n",
       "\n",
       "                                            answer  \n",
       "0                    i'm fine. how about yourself?  \n",
       "1              i'm pretty good. thanks for asking.  \n",
       "2                no problem. so how have you been?  \n",
       "3                 i've been great. what about you?  \n",
       "4         i've been good. i'm in school right now.  \n",
       "5                        what school do you go to?  \n",
       "6                                     i go to pcc.  \n",
       "7                            do you like it there?  \n",
       "8             it's okay. it's a really big campus.  \n",
       "9                           good luck with school.  \n",
       "10                            thank you very much.  \n",
       "11                  i'm doing well. how about you?  \n",
       "12                           never better, thanks.  \n",
       "13                    so how have you been lately?  \n",
       "14            i've actually been pretty good. you?  \n",
       "15               i'm actually in school right now.  \n",
       "16                     which school do you attend?  \n",
       "17                    i'm attending pcc right now.  \n",
       "18                      are you enjoying it there?  \n",
       "19  it's not bad. there are a lot of people there.  \n",
       "20                            good luck with that.  \n",
       "21                                         thanks.  \n",
       "22                i'm doing great. what about you?  \n",
       "23               i'm absolutely lovely, thank you.  \n",
       "24                everything's been good with you?  \n",
       "25      i haven't been better. how about yourself?  \n",
       "26                      i started school recently.  \n",
       "27                  where are you going to school?  \n",
       "28                               i'm going to pcc.  \n",
       "29                      how do you like it so far?  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/cristianEmel/nlp/refs/heads/main/Conversation.csv\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "df = pd.read_csv(io.StringIO(response.text), sep=',', on_bad_lines='skip')\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHBRAXPl-3dz",
    "outputId": "668ab425-ec97-4cbc-babe-c428a0c5ce2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows utilizadas: 3477\n"
     ]
    }
   ],
   "source": [
    "chat_in = []\n",
    "chat_out = []\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "max_len = 60\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove special characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "      # vamos separando el texto en \"preguntas\" (chat_in)\n",
    "      # y \"respuestas\" (chat_out)\n",
    "      chat_in = preprocess_text(row['question'])\n",
    "      chat_out = preprocess_text(row['answer'])\n",
    "\n",
    "      if pd.isna(chat_in) or pd.isna(chat_out):\n",
    "        continue\n",
    "\n",
    "      if len(chat_in) >= max_len or len(chat_out) >= max_len:\n",
    "          continue\n",
    "\n",
    "      input_sentence, output = chat_in, chat_out\n",
    "\n",
    "      # output sentence (decoder_output) tiene <eos>\n",
    "      output_sentence = output + ' <eos>'\n",
    "      # output sentence input (decoder_input) tiene <sos>\n",
    "      output_sentence_input = '<sos> ' + output\n",
    "\n",
    "      input_sentences.append(input_sentence)\n",
    "      output_sentences.append(output_sentence)\n",
    "      output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07L1qj8pC_l6",
    "outputId": "be26c0fc-ee8b-4025-fefe-079ffdae791a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('im fine how about yourself',\n",
       " 'im pretty good thanks for asking <eos>',\n",
       " '<sos> im pretty good thanks for asking')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[1], output_sentences[1], output_sentences_inputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M5s2L4g6y2aR"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-ynUNP5xp6"
   },
   "source": [
    "### 2 - Preprocesamiento\n",
    "Realizar el preprocesamiento necesario para obtener:\n",
    "- word2idx_inputs, max_input_len\n",
    "- word2idx_outputs, max_out_len, num_words_output\n",
    "- encoder_input_sequences, decoder_output_sequences, decoder_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RgEoVRJy4nq",
    "outputId": "11224fa5-87c6-4d54-d34d-22e5bf753664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 2254\n",
      "Sentencia de entrada más larga: 16\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Sentencia de entrada más larga:\", max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsWg4br8Bmmd",
    "outputId": "62028dd2-3e2c-48f6-8131-b74f6036024e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 2310\n",
      "Sentencia de salida más larga: 17\n"
     ]
    }
   ],
   "source": [
    "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
    "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
    "\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Sentencia de salida más larga:\", max_out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JC7c_XBCAhs",
    "outputId": "7569decb-31e6-437b-e0d5-9bfe03296886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows del dataset: 3477\n",
      "encoder_input_sequences shape: (3477, 16)\n",
      "decoder_input_sequences shape: (3477, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldlYHkJsDCV0",
    "outputId": "bf30fe44-e1d6-4243-e94c-8592992493ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output_sequences shape: (3477, 17)\n"
     ]
    }
   ],
   "source": [
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_output_sequences shape:\", decoder_output_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BgmrgKRTDSKn",
    "outputId": "90b440be-95de-4db2-d69c-67afbcbde375"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_size: 16\n",
      "decoder_input_size: 17\n",
      "Output dim 2311\n"
     ]
    }
   ],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, encoder_input, decoder_input, decoder_output):\n",
    "        # Convertir los arrays de numpy a tensores.\n",
    "        # pytorch espera en general entradas 32bits\n",
    "        self.encoder_inputs = torch.from_numpy(encoder_input.astype(np.int32))\n",
    "        self.decoder_inputs = torch.from_numpy(decoder_input.astype(np.int32))\n",
    "        # Transformar los datos a oneHotEncoding\n",
    "        # la loss function esperan la salida float\n",
    "        self.decoder_outputs = F.one_hot(torch.from_numpy(decoder_output).to(torch.int64), num_classes=num_words_output).float()\n",
    "\n",
    "        self.len = self.decoder_outputs.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.encoder_inputs[index], self.decoder_inputs[index], self.decoder_outputs[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "data_set = Data(encoder_input_sequences, decoder_input_sequences, decoder_output_sequences)\n",
    "\n",
    "encoder_input_size = data_set.encoder_inputs.shape[1]\n",
    "print(\"encoder_input_size:\", encoder_input_size)\n",
    "\n",
    "decoder_input_size = data_set.decoder_inputs.shape[1]\n",
    "print(\"decoder_input_size:\", decoder_input_size)\n",
    "\n",
    "output_dim = data_set.decoder_outputs.shape[2]\n",
    "print(\"Output dim\", output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbt0FEbzDqM0",
    "outputId": "04aed62c-d40f-4f30-fce5-f5dad8c56ca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 2782\n",
      "Tamaño del conjunto de validacion: 695\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "valid_set_size = int(data_set.len * 0.2)\n",
    "train_set_size = data_set.len - valid_set_size\n",
    "\n",
    "train_set = torch.utils.data.Subset(data_set, range(train_set_size))\n",
    "valid_set = torch.utils.data.Subset(data_set, range(train_set_size, data_set.len))\n",
    "\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", len(train_set))\n",
    "print(\"Tamaño del conjunto de validacion:\", len(valid_set))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJIsLBbj6rg"
   },
   "source": [
    "### 3 - Preparar los embeddings\n",
    "Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFQzol50Er4B",
    "outputId": "642b911a-73b9-4389-c864-ca5d00d81375"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already downloaded.\n",
      "Extracted files to ./fasttext_files/\n",
      "Found .vec file: ./fasttext_files/wiki-news-300d-1M-subword.vec\n",
      "Saved embeddings to fasttext.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import pickle\n",
    "\n",
    "# URL of the .zip file on Google Drive (replace with your file's ID)\n",
    "url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M-subword.vec.zip'\n",
    "\n",
    "# Output path where you want to save the downloaded file\n",
    "zip_output = 'fasttext.zip'\n",
    "\n",
    "# Download the .zip file\n",
    "if not os.path.exists(zip_output):\n",
    "    gdown.download(url, zip_output, quiet=False)\n",
    "else:\n",
    "    print(\"File already downloaded.\")\n",
    "\n",
    "# Extract the .zip file\n",
    "extract_dir = './fasttext_files/'\n",
    "if not os.path.exists(extract_dir):\n",
    "    os.makedirs(extract_dir)\n",
    "\n",
    "with zipfile.ZipFile(zip_output, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "    print(f\"Extracted files to {extract_dir}\")\n",
    "\n",
    "# Assuming the .zip file contains a .vec file, find it\n",
    "vec_file = None\n",
    "for file_name in os.listdir(extract_dir):\n",
    "    if file_name.endswith('.vec'):\n",
    "        vec_file = os.path.join(extract_dir, file_name)\n",
    "        break\n",
    "\n",
    "if vec_file:\n",
    "    print(f\"Found .vec file: {vec_file}\")\n",
    "\n",
    "    # Load the .vec file and prepare it as a dictionary (word embeddings)\n",
    "    embeddings = {}\n",
    "    with open(vec_file, 'r', encoding='utf-8') as f:\n",
    "        # Skip the header line that contains vocab size and embedding dimension\n",
    "        first_line = f.readline().split()\n",
    "        vocab_size, embedding_dim = int(first_line[0]), int(first_line[1])\n",
    "\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = list(map(float, parts[1:]))\n",
    "            embeddings[word] = vector\n",
    "\n",
    "    # Save the embeddings as a .pkl file\n",
    "    fasttext_pkl = 'fasttext.pkl'\n",
    "    with open(fasttext_pkl, 'wb') as pkl_file:\n",
    "        pickle.dump(embeddings, pkl_file)\n",
    "\n",
    "    print(f\"Saved embeddings to {fasttext_pkl}\")\n",
    "else:\n",
    "    print(\"No .vec file found in the extracted .zip file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Ey5W3GlhEz_H"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "class WordsEmbeddings(object):\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        # load the embeddings\n",
    "        words_embedding_pkl = Path(self.PKL_PATH)\n",
    "        if not words_embedding_pkl.is_file():\n",
    "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
    "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
    "            embeddings = self.convert_model_to_pickle()\n",
    "        else:\n",
    "            embeddings = self.load_model_from_pickle()\n",
    "        self.embeddings = embeddings\n",
    "        index = np.arange(len(self.embeddings))\n",
    "\n",
    "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
    "        self.word2idx = dict(zip(list(self.embeddings.keys()), index)) # Modification: Use keys for word2idx\n",
    "        self.idx2word = dict(zip(index, list(self.embeddings.keys()))) #\n",
    "\n",
    "    def get_words_embeddings(self, words):\n",
    "        words_idxs = self.words2idxs(words)\n",
    "\n",
    "        # Modification: Return embeddings based on words_idxs\n",
    "        return np.array([self.embeddings.get(self.idx2word.get(idx, '-1'), np.zeros(self.N_FEATURES)) for idx in words_idxs])\n",
    "\n",
    "\n",
    "    def words2idxs(self, words):\n",
    "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
    "\n",
    "    def idxs2words(self, idxs):\n",
    "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
    "\n",
    "    def load_model_from_pickle(self):\n",
    "        self.logger.debug(\n",
    "            'loading words embeddings from pickle {}'.format(\n",
    "                self.PKL_PATH\n",
    "            )\n",
    "        )\n",
    "        max_bytes = 2**28 - 1 # 256MB\n",
    "        bytes_in = bytearray(0)\n",
    "        input_size = os.path.getsize(self.PKL_PATH)\n",
    "        with open(self.PKL_PATH, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "        embeddings = pickle.loads(bytes_in)\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "    def convert_model_to_pickle(self):\n",
    "        # create a numpy strctured array:\n",
    "        # word     embedding\n",
    "        # U50      np.float32[]\n",
    "        # word_1   a, b, c\n",
    "        # word_2   d, e, f\n",
    "        # ...\n",
    "        # word_n   g, h, i\n",
    "        self.logger.debug(\n",
    "            'converting and loading words embeddings from text file {}'.format(\n",
    "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
    "            )\n",
    "        )\n",
    "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
    "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
    "        structure = np.dtype(structure)\n",
    "        # load numpy array from disk using a generator\n",
    "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
    "            embeddings_gen = (\n",
    "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
    "                if len(line.split()[1:]) == self.N_FEATURES\n",
    "            )\n",
    "            embeddings = np.fromiter(embeddings_gen, structure)\n",
    "        # add a null embedding\n",
    "        null_embedding = np.array(\n",
    "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
    "            dtype=structure\n",
    "        )\n",
    "        embeddings = np.concatenate([embeddings, null_embedding])\n",
    "        # dump numpy array to disk using pickle\n",
    "        max_bytes = 2**28 - 1 # # 256MB\n",
    "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.PKL_PATH, 'wb') as f_out:\n",
    "            for idx in range(0, len(bytes_out), max_bytes):\n",
    "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class GloveEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
    "    PKL_PATH = 'gloveembedding.pkl'\n",
    "    N_FEATURES = 50\n",
    "    WORD_MAX_SIZE = 60\n",
    "\n",
    "class FasttextEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
    "    PKL_PATH = 'fasttext.pkl'\n",
    "    N_FEATURES = 300\n",
    "    WORD_MAX_SIZE = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wyHXPwXNTs2t"
   },
   "outputs": [],
   "source": [
    "model_embeddings = FasttextEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "gkTr5n8nE_qH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing embedding matrix...\n",
      "number of null word embeddings: 1\n"
     ]
    }
   ],
   "source": [
    "# Crear la Embedding matrix de las secuencias\n",
    "# en ingles\n",
    "\n",
    "print('preparing embedding matrix...')\n",
    "embed_dim = model_embeddings.N_FEATURES\n",
    "words_not_found = []\n",
    "\n",
    "# word_index provieen del tokenizer\n",
    "\n",
    "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        words_not_found.append(word)\n",
    "\n",
    "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM"
   },
   "source": [
    "### 4 - Entrenar el modelo\n",
    "Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SjUT_OJsFG55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Seq2Seq                                  [1, 17, 2311]             --\n",
       "├─Encoder: 1-1                           [1, 1, 128]               --\n",
       "│    └─Embedding: 2-1                    [1, 16, 300]              (676,200)\n",
       "│    └─LSTM: 2-2                         [1, 16, 128]              220,160\n",
       "├─Decoder: 1-2                           [1, 2311]                 --\n",
       "│    └─Embedding: 2-3                    [1, 1, 300]               693,300\n",
       "│    └─LSTM: 2-4                         [1, 1, 128]               220,160\n",
       "│    └─Linear: 2-5                       [1, 2311]                 298,119\n",
       "│    └─Softmax: 2-6                      [1, 2311]                 --\n",
       "├─Decoder: 1-3                           [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-7                    [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-8                         [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-9                       [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-10                     [1, 2311]                 --\n",
       "├─Decoder: 1-4                           [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-11                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-12                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-13                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-14                     [1, 2311]                 --\n",
       "├─Decoder: 1-5                           [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-15                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-16                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-17                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-18                     [1, 2311]                 --\n",
       "├─Decoder: 1-6                           [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-19                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-20                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-21                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-22                     [1, 2311]                 --\n",
       "├─Decoder: 1-7                           [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-23                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-24                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-25                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-26                     [1, 2311]                 --\n",
       "├─Decoder: 1-8                           [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-27                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-28                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-29                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-30                     [1, 2311]                 --\n",
       "├─Decoder: 1-9                           [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-31                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-32                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-33                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-34                     [1, 2311]                 --\n",
       "├─Decoder: 1-10                          [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-35                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-36                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-37                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-38                     [1, 2311]                 --\n",
       "├─Decoder: 1-11                          [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-39                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-40                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-41                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-42                     [1, 2311]                 --\n",
       "├─Decoder: 1-12                          [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-43                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-44                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-45                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-46                     [1, 2311]                 --\n",
       "├─Decoder: 1-13                          [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-47                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-48                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-49                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-50                     [1, 2311]                 --\n",
       "├─Decoder: 1-14                          [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-51                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-52                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-53                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-54                     [1, 2311]                 --\n",
       "├─Decoder: 1-15                          [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-55                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-56                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-57                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-58                     [1, 2311]                 --\n",
       "├─Decoder: 1-16                          [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-59                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-60                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-61                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-62                     [1, 2311]                 --\n",
       "├─Decoder: 1-17                          [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-63                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-64                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-65                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-66                     [1, 2311]                 --\n",
       "├─Decoder: 1-18                          [1, 2311]                 (recursive)\n",
       "│    └─Embedding: 2-67                   [1, 1, 300]               (recursive)\n",
       "│    └─LSTM: 2-68                        [1, 1, 128]               (recursive)\n",
       "│    └─Linear: 2-69                      [1, 2311]                 (recursive)\n",
       "│    └─Softmax: 2-70                     [1, 2311]                 --\n",
       "==========================================================================================\n",
       "Total params: 2,107,939\n",
       "Trainable params: 1,431,739\n",
       "Non-trainable params: 676,200\n",
       "Total mult-adds (Units.MEGABYTES): 24.80\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.43\n",
       "Params size (MB): 8.43\n",
       "Estimated Total Size (MB): 8.86\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
    "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
    "        self.lstm_size = 128\n",
    "        self.num_layers = 1\n",
    "        self.embedding_dim = embed_dim\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = False  # marcar como layer no entrenable (freeze)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
    "                            num_layers=self.num_layers) # LSTM layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        lstm_output, (ht, ct) = self.lstm(out)\n",
    "        return (ht, ct)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, output_dim):\n",
    "        super().__init__()\n",
    "        # num_embeddings = vocab_size, definido por le Tokenizador\n",
    "        # embedding_dim = 50 --> dimensión de los embeddings utilizados\n",
    "        self.lstm_size = 128\n",
    "        self.num_layers = 1\n",
    "        self.embedding_dim = embed_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_size, batch_first=True,\n",
    "                            num_layers=self.num_layers) # LSTM layer\n",
    "        self.fc1 = nn.Linear(in_features=self.lstm_size, out_features=self.output_dim) # Fully connected layer\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1) # normalize in dim 1\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        out = self.embedding(x)\n",
    "        lstm_output, (ht, ct) = self.lstm(out, prev_state)\n",
    "        out = self.softmax(self.fc1(lstm_output[:,-1,:])) # take last output (last seq)\n",
    "        return out, (ht, ct)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        assert encoder.lstm_size == decoder.lstm_size, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.num_layers == decoder.num_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, encoder_input, decoder_input):\n",
    "        batch_size = decoder_input.shape[0]\n",
    "        decoder_input_len = decoder_input.shape[1]\n",
    "        vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # tensor para almacenar la salida\n",
    "        # (batch_size, sentence_len, one_hot_size)\n",
    "        outputs = torch.zeros(batch_size, decoder_input_len, vocab_size)\n",
    "\n",
    "        # ultimo hidden state del encoder, primer estado oculto del decoder\n",
    "        prev_state = self.encoder(encoder_input)\n",
    "\n",
    "        # En la primera iteracion se toma el primer token de target (<sos>)\n",
    "        input = decoder_input[:, 0:1]\n",
    "\n",
    "        for t in range(decoder_input_len):\n",
    "            # t --> token index\n",
    "\n",
    "            # utilizamos método \"teacher forcing\", es decir que durante\n",
    "            # el entrenamiento no realimentamos la salida del decoder\n",
    "            # sino el token correcto que sigue en target\n",
    "            input = decoder_input[:, t:t+1]\n",
    "\n",
    "            # ingresar cada token embedding, uno por uno junto al hidden state\n",
    "            # recibir el output del decoder (softmax)\n",
    "            output, prev_state = self.decoder(input, prev_state)\n",
    "            top1 = output.argmax(1).view(-1, 1)\n",
    "\n",
    "            # Sino se usará \"teacher forcing\" habría que descomentar\n",
    "            # esta linea.\n",
    "            # Hay ejemplos dandos vuelta en donde se utilza un random\n",
    "            # para ver en cada vuelta que técnica se aplica\n",
    "            #input = top1\n",
    "\n",
    "            # guardar cada salida (softmax)\n",
    "            outputs[:, t, :] = output\n",
    "\n",
    "        return outputs\n",
    "\n",
    "encoder = Encoder(vocab_size=nb_words)\n",
    "if cuda: encoder.cuda()\n",
    "# decoder --> vocab_size == output_dim --> porque recibe y devuelve palabras en el mismo vocabulario\n",
    "decoder = Decoder(vocab_size=num_words_output, output_dim=num_words_output)\n",
    "if cuda: decoder.cuda()\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "if cuda: model.cuda()\n",
    "\n",
    "encoder_input = data_set[0:1][0]\n",
    "decoder_input = data_set[0:1][1]\n",
    "if cuda:\n",
    "    encoder_input = encoder_input.cuda()\n",
    "    decoder_input = decoder_input.cuda()\n",
    "\n",
    "# Crear el optimizador la una función de error\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Para clasificación multi categórica\n",
    "\n",
    "summary(model, input_data=(encoder_input, decoder_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "o4lcFLEQJB3Q"
   },
   "outputs": [],
   "source": [
    "def sequence_acc(y_pred, y_test):\n",
    "    y_pred_tag = y_pred.data.max(dim=-1,keepdim=True)[1]\n",
    "    y_test_tag = y_test.data.max(dim=-1,keepdim=True)[1]\n",
    "\n",
    "    batch_size = y_pred_tag.shape[0]\n",
    "    batch_acc = torch.zeros(batch_size)\n",
    "    for b in range(batch_size):\n",
    "        correct_results_sum = (y_pred_tag[b] == y_test_tag[b]).sum().float()\n",
    "        batch_acc[b] = correct_results_sum / y_pred_tag[b].shape[0]\n",
    "\n",
    "    correct_results_sum = batch_acc.sum().float()\n",
    "    acc = correct_results_sum / batch_size\n",
    "    return acc\n",
    "\n",
    "def train(model, train_loader, valid_loader, optimizer, criterion, epochs=100):\n",
    "    # Defino listas para realizar graficas de los resultados\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "    valid_loss = []\n",
    "    valid_accuracy = []\n",
    "\n",
    "    # Defino mi loop de entrenamiento\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_accuracy = 0.0\n",
    "\n",
    "        for train_encoder_input, train_decoder_input, train_target in train_loader:\n",
    "            # Seteo los gradientes en cero ya que, por defecto, PyTorch\n",
    "            # los va acumulando\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(train_encoder_input.to(device), train_decoder_input.to(device))\n",
    "\n",
    "            # Computo el error de la salida comparando contra las etiquetas\n",
    "            # por cada token en cada batch (sequence_loss)\n",
    "            loss = 0\n",
    "            for t in range(train_decoder_input.shape[1]):\n",
    "                loss += criterion(output[:, t, :], train_target[:, t, :])\n",
    "\n",
    "            # Almaceno el error del batch para luego tener el error promedio de la epoca\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "            # Computo el nuevo set de gradientes a lo largo de toda la red\n",
    "            loss.backward()\n",
    "\n",
    "            # Realizo el paso de optimizacion actualizando los parametros de toda la red\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculo el accuracy del batch\n",
    "            accuracy = sequence_acc(output, train_target)\n",
    "            # Almaceno el accuracy del batch para luego tener el accuracy promedio de la epoca\n",
    "            epoch_train_accuracy += accuracy.item()\n",
    "\n",
    "        # Calculo la media de error para la epoca de entrenamiento.\n",
    "        # La longitud de train_loader es igual a la cantidad de batches dentro de una epoca.\n",
    "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)\n",
    "        train_accuracy.append(epoch_train_accuracy)\n",
    "\n",
    "        # Realizo el paso de validación computando error y accuracy, y\n",
    "        # almacenando los valores para imprimirlos y graficarlos\n",
    "        valid_encoder_input, valid_decoder_input, valid_target = next(iter(valid_loader))\n",
    "        output = model(valid_encoder_input.to(device), valid_decoder_input.to(device))\n",
    "\n",
    "        epoch_valid_loss = 0\n",
    "        for t in range(train_decoder_input.shape[1]):\n",
    "                epoch_valid_loss += criterion(output[:, t, :], valid_target[:, t, :])\n",
    "        epoch_valid_loss = epoch_valid_loss.item()\n",
    "\n",
    "        valid_loss.append(epoch_valid_loss)\n",
    "\n",
    "        # Calculo el accuracy de la epoch\n",
    "        epoch_valid_accuracy = sequence_acc(output, valid_target).item()\n",
    "        valid_accuracy.append(epoch_valid_accuracy)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{epochs} - Train loss {epoch_train_loss:.3f} - Train accuracy {epoch_train_accuracy:.3f} - Valid Loss {epoch_valid_loss:.3f} - Valid accuracy {epoch_valid_accuracy:.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"loss\": train_loss,\n",
    "        \"accuracy\": train_accuracy,\n",
    "        \"val_loss\": valid_loss,\n",
    "        \"val_accuracy\": valid_accuracy,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "52DZkzeHGCyb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20 - Train loss 128.923 - Train accuracy 0.484 - Valid Loss 122.272 - Valid accuracy 0.562\n",
      "Epoch: 2/20 - Train loss 121.678 - Train accuracy 0.591 - Valid Loss 122.127 - Valid accuracy 0.562\n",
      "Epoch: 3/20 - Train loss 121.633 - Train accuracy 0.592 - Valid Loss 122.113 - Valid accuracy 0.563\n",
      "Epoch: 4/20 - Train loss 121.617 - Train accuracy 0.593 - Valid Loss 122.110 - Valid accuracy 0.564\n",
      "Epoch: 5/20 - Train loss 121.606 - Train accuracy 0.594 - Valid Loss 122.110 - Valid accuracy 0.564\n",
      "Epoch: 6/20 - Train loss 121.608 - Train accuracy 0.593 - Valid Loss 122.112 - Valid accuracy 0.563\n",
      "Epoch: 7/20 - Train loss 121.606 - Train accuracy 0.593 - Valid Loss 122.113 - Valid accuracy 0.563\n",
      "Epoch: 8/20 - Train loss 121.600 - Train accuracy 0.594 - Valid Loss 122.120 - Valid accuracy 0.562\n",
      "Epoch: 9/20 - Train loss 121.604 - Train accuracy 0.593 - Valid Loss 122.128 - Valid accuracy 0.562\n",
      "Epoch: 10/20 - Train loss 121.588 - Train accuracy 0.594 - Valid Loss 122.122 - Valid accuracy 0.562\n",
      "Epoch: 11/20 - Train loss 121.595 - Train accuracy 0.594 - Valid Loss 122.120 - Valid accuracy 0.563\n",
      "Epoch: 12/20 - Train loss 121.588 - Train accuracy 0.594 - Valid Loss 122.119 - Valid accuracy 0.563\n",
      "Epoch: 13/20 - Train loss 121.591 - Train accuracy 0.594 - Valid Loss 122.118 - Valid accuracy 0.563\n",
      "Epoch: 14/20 - Train loss 121.587 - Train accuracy 0.594 - Valid Loss 122.117 - Valid accuracy 0.563\n",
      "Epoch: 15/20 - Train loss 121.584 - Train accuracy 0.594 - Valid Loss 122.117 - Valid accuracy 0.563\n",
      "Epoch: 16/20 - Train loss 121.589 - Train accuracy 0.594 - Valid Loss 122.116 - Valid accuracy 0.563\n",
      "Epoch: 17/20 - Train loss 121.588 - Train accuracy 0.594 - Valid Loss 122.115 - Valid accuracy 0.563\n",
      "Epoch: 18/20 - Train loss 121.586 - Train accuracy 0.594 - Valid Loss 122.119 - Valid accuracy 0.563\n",
      "Epoch: 19/20 - Train loss 121.519 - Train accuracy 0.599 - Valid Loss 122.046 - Valid accuracy 0.567\n",
      "Epoch: 20/20 - Train loss 121.467 - Train accuracy 0.602 - Valid Loss 122.012 - Valid accuracy 0.569\n"
     ]
    }
   ],
   "source": [
    "history1 = train(model,\n",
    "                train_loader,\n",
    "                valid_loader,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                epochs=20\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Xm_ea7-UMU3j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Emel\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "c:\\Users\\Emel\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "c:\\Users\\Emel\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "c:\\Users\\Emel\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_count = range(1, len(history1['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history1['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=history1['val_accuracy'], label='valid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NPBoV_vvLYJN"
   },
   "outputs": [],
   "source": [
    "# Armar lo conversores de indice a palabra:\n",
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbwn0ekDy_s2"
   },
   "source": [
    "### 5 - Inferencia\n",
    "Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRw4eF35L0ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Hi\n",
      "Representacion en vector de tokens de ids [903]\n",
      "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 903]]\n",
      "Response: i you i you i\n"
     ]
    }
   ],
   "source": [
    "def response_sentence(input_test):\n",
    "    print('Input:', input_test)\n",
    "    integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "    print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
    "    encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "    print(\"Padding del vector:\", encoder_sequence_test)\n",
    "    encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
    "\n",
    "    # Se obtiene la salida del encoder (el estado oculto para el decoder)\n",
    "    prev_state = model.encoder(encoder_sequence_test_tensor.to(device))\n",
    "\n",
    "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "    target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32))\n",
    "\n",
    "    # Se obtiene la primera palabra de la secuencia de salida del decoder\n",
    "    output, prev_state = model.decoder(target_seq_tensor.to(device), prev_state)\n",
    "\n",
    "    output_sentence = []\n",
    "    for _ in range(max_out_len):\n",
    "        # Predicción del próximo elemento\n",
    "        output, prev_state = model.decoder(target_seq_tensor.to(device), prev_state)\n",
    "        top1 = output.argmax(1).view(-1, 1)\n",
    "        idx = int(top1.cpu())\n",
    "\n",
    "        # Transformar ídx a palabra\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Actualizar los estados dado la ultimo prediccion\n",
    "        prev_state = prev_state\n",
    "\n",
    "        # Actualizar secuencia de entrada con la salida (re-alimentacion)\n",
    "        target_seq_tensor = top1\n",
    "\n",
    "    return ' '.join(output_sentence)\n",
    "\n",
    "\n",
    "input_test = \"Do you read?\"\n",
    "translation = response_sentence(input_test)\n",
    "print('Response:', translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se vio una generacion satisfactoria de respuestas. Con distintas entradas, la respuesta era similar: i you i you.\n",
    "Se probara reimplementando el metodo con uno funcion de seleccion de la palabra distinta, en este caso binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Do you read?\n",
      "Representacion en vector de tokens de ids [8, 2, 375]\n",
      "Padding del vector: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   8   2 375]]\n",
      "Response: meant placed lately poker pets favorite teach thought kids upset driving anniversary stock screws cop mans smoker\n"
     ]
    }
   ],
   "source": [
    "def response_sentence(input_test):\n",
    "    print('Input:', input_test)\n",
    "    integer_seq_test = input_tokenizer.texts_to_sequences([input_test])[0]\n",
    "    print(\"Representacion en vector de tokens de ids\", integer_seq_test)\n",
    "    encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "    print(\"Padding del vector:\", encoder_sequence_test)\n",
    "    encoder_sequence_test_tensor = torch.from_numpy(encoder_sequence_test.astype(np.int32))\n",
    "    # Se transforma la sequencia de entrada a los stados \"h\" y \"c\" de la LSTM\n",
    "    # para enviar la primera vez al decoder\"\n",
    "    prev_state = model.encoder(encoder_sequence_test_tensor.to(device))\n",
    "\n",
    "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "    target_seq_tensor = torch.from_numpy(target_seq.astype(np.int32))\n",
    "\n",
    "    # Se obtiene el indice que finaliza la inferencia\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "\n",
    "    output_sentence = []\n",
    "    for _ in range(max_out_len):\n",
    "        # Predicción del próximo elemento\n",
    "        output, new_prev_state = model.decoder(target_seq_tensor.to(device), prev_state)\n",
    "        probs = F.softmax(output, dim=-1)  # Apply softmax to get probabilities\n",
    "        top1 = torch.multinomial(probs, 1).view(-1, 1)  # Sample from the probabilities\n",
    "        idx = int(top1.cpu())\n",
    "\n",
    "        # Si es \"end of sentece <eos>\" se acaba\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        # Transformar ídx a palabra\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Actualizar los estados dado la ultimo prediccion\n",
    "        prev_state = new_prev_state\n",
    "\n",
    "        # Actualizar secuencia de entrada con la salida (re-alimentacion)\n",
    "        target_seq_tensor = top1\n",
    "\n",
    "    return ' '.join(output_sentence)\n",
    "\n",
    "input_test = \"Do you read?\"\n",
    "translation = response_sentence(input_test)\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien, se vio cambio al ya no ser la misma palabra. No se vio correlacion entre ellos"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
